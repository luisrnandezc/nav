2025-11-22 22:22:21,854 - INFO - ================================================================================
2025-11-22 22:22:21,854 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 1
2025-11-22 22:22:21,854 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-22 22:22:21,854 - INFO - Report namespace created - date: 2025-11-23, time: 22:17:00, area: OPERATIONS, description length: 228
2025-11-22 22:22:21,854 - INFO - Rendered prompt length: 6576 characters
2025-11-22 22:22:21,854 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-22 22:22:21,854 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-22 22:22:21,854 - INFO - Attempting to initialize OpenAI client
2025-11-22 22:22:22,210 - INFO - OpenAI client initialized successfully
2025-11-22 22:22:22,210 - INFO - Making API request to OpenAI responses endpoint
2025-11-22 22:22:22,210 - INFO - Model: gpt-5, reasoning: high, text verbosity: high
2025-11-22 22:25:25,130 - ERROR - Exception during OpenAI operation: Connection error. (Type: APIConnectionError)
Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-22 22:25:25,162 - ERROR - Full traceback: Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

2025-11-22 22:25:25,162 - INFO - ================================================================================
2025-11-22 22:27:16,965 - INFO - ================================================================================
2025-11-22 22:27:16,966 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 1
2025-11-22 22:27:16,966 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-22 22:27:16,966 - INFO - Report namespace created - date: 2025-11-23, time: 22:17:00, area: OPERATIONS, description length: 228
2025-11-22 22:27:16,966 - INFO - Rendered prompt length: 6576 characters
2025-11-22 22:27:16,966 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-22 22:27:16,966 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-22 22:27:16,967 - INFO - Attempting to initialize OpenAI client
2025-11-22 22:27:17,258 - INFO - OpenAI client initialized successfully
2025-11-22 22:27:17,258 - INFO - Making API request to OpenAI responses endpoint
2025-11-22 22:27:17,258 - INFO - Model: gpt-5, reasoning: high, text verbosity: high
2025-11-22 22:30:20,128 - ERROR - Exception during OpenAI operation: Connection error. (Type: APIConnectionError)
Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-22 22:30:20,136 - ERROR - Full traceback: Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

2025-11-22 22:30:20,136 - INFO - ================================================================================
2025-11-22 22:30:28,919 - INFO - ================================================================================
2025-11-22 22:30:28,919 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 1
2025-11-22 22:30:28,919 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-22 22:30:28,919 - INFO - Report namespace created - date: 2025-11-23, time: 22:17:00, area: OPERATIONS, description length: 228
2025-11-22 22:30:28,920 - INFO - Rendered prompt length: 6576 characters
2025-11-22 22:30:28,920 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-22 22:30:28,920 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-22 22:30:28,920 - INFO - Attempting to initialize OpenAI client
2025-11-22 22:30:29,238 - INFO - OpenAI client initialized successfully
2025-11-22 22:30:29,238 - INFO - Making API request to OpenAI responses endpoint
2025-11-22 22:30:29,238 - INFO - Model: gpt-5-nano, reasoning: medium, text verbosity: medium
2025-11-22 22:31:09,594 - INFO - API request completed successfully
2025-11-22 22:31:09,594 - INFO - Response content extracted, length: 1251 characters
2025-11-22 22:31:09,594 - INFO - ================================================================================
2025-11-23 11:47:54,953 - INFO - ================================================================================
2025-11-23 11:47:54,953 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 2
2025-11-23 11:47:54,953 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-23 11:47:54,953 - INFO - Report namespace created - date: 2025-11-23, time: 11:45:00, area: OPERATIONS, description length: 162
2025-11-23 11:47:54,960 - INFO - Rendered prompt length: 6510 characters
2025-11-23 11:47:54,960 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 11:47:54,960 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 11:47:54,960 - INFO - Attempting to initialize OpenAI client
2025-11-23 11:47:55,266 - INFO - OpenAI client initialized successfully
2025-11-23 11:47:55,266 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 11:47:55,266 - INFO - Model: gpt-5-nano, reasoning: medium, text verbosity: medium
2025-11-23 11:48:25,173 - INFO - API request completed successfully
2025-11-23 11:48:25,173 - INFO - Response content extracted, length: 920 characters
2025-11-23 11:48:25,173 - INFO - ================================================================================
2025-11-23 11:59:10,591 - INFO - ================================================================================
2025-11-23 11:59:10,591 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 3
2025-11-23 11:59:10,591 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-23 11:59:10,591 - INFO - Report namespace created - date: 2025-11-23, time: 11:58:00, area: OPERATIONS, description length: 88
2025-11-23 11:59:10,591 - INFO - Rendered prompt length: 6436 characters
2025-11-23 11:59:10,591 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 11:59:10,591 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 11:59:10,591 - INFO - Attempting to initialize OpenAI client
2025-11-23 11:59:10,891 - INFO - OpenAI client initialized successfully
2025-11-23 11:59:10,891 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 11:59:10,907 - INFO - Model: gpt-5-nano, reasoning: medium, text verbosity: medium
2025-11-23 12:02:13,741 - ERROR - Exception during OpenAI operation: Connection error. (Type: APIConnectionError)
Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-23 12:02:13,753 - ERROR - Full traceback: Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

2025-11-23 12:02:13,753 - INFO - ================================================================================
2025-11-23 12:02:48,778 - INFO - ================================================================================
2025-11-23 12:02:48,778 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 3
2025-11-23 12:02:48,778 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-23 12:02:48,778 - INFO - Report namespace created - date: 2025-11-23, time: 11:58:00, area: OPERATIONS, description length: 88
2025-11-23 12:02:48,778 - INFO - Rendered prompt length: 6436 characters
2025-11-23 12:02:48,779 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 12:02:48,779 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 12:02:48,779 - INFO - Attempting to initialize OpenAI client
2025-11-23 12:02:49,099 - INFO - OpenAI client initialized successfully
2025-11-23 12:02:49,100 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 12:02:49,100 - INFO - Model: gpt-5-nano, reasoning: medium, text verbosity: medium
2025-11-23 12:05:40,473 - ERROR - Exception during OpenAI operation: Connection error. (Type: APIConnectionError)
Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-23 12:05:40,503 - ERROR - Full traceback: Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 72, in map_httpcore_exceptions
    yield
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\httpx\_transports\default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\luish\projects\nav\config\sms\scripts\..\..\sms\views.py", line 145, in run_ai_analysis_for_voluntary_hazard_report
    response = client.responses.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\resources\responses\responses.py", line 840, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luish\projects\nav\venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

2025-11-23 12:05:40,523 - INFO - ================================================================================
2025-11-23 12:06:15,546 - INFO - ================================================================================
2025-11-23 12:06:15,546 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 3
2025-11-23 12:06:15,546 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-23 12:06:15,546 - INFO - Report namespace created - date: 2025-11-23, time: 11:58:00, area: OPERATIONS, description length: 88
2025-11-23 12:06:15,546 - INFO - Rendered prompt length: 6436 characters
2025-11-23 12:06:15,546 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 12:06:15,546 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 12:06:15,546 - INFO - Attempting to initialize OpenAI client
2025-11-23 12:06:15,899 - INFO - OpenAI client initialized successfully
2025-11-23 12:06:15,899 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 12:06:15,899 - INFO - Model: gpt-5-nano, reasoning: medium, text verbosity: medium
2025-11-23 12:09:56,645 - INFO - ================================================================================
2025-11-23 12:09:56,646 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 3
2025-11-23 12:09:56,646 - INFO - AI analysis prompt loaded, length: 6401 characters
2025-11-23 12:09:56,646 - INFO - Report namespace created - date: 2025-11-23, time: 11:58:00, area: OPERATIONS, description length: 88
2025-11-23 12:09:56,647 - INFO - Rendered prompt length: 6436 characters
2025-11-23 12:09:56,647 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 12:09:56,647 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 12:09:56,647 - INFO - Attempting to initialize OpenAI client
2025-11-23 12:09:56,951 - INFO - OpenAI client initialized successfully
2025-11-23 12:09:56,951 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 12:09:56,951 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium
2025-11-23 12:10:12,415 - INFO - API request completed successfully
2025-11-23 12:10:12,416 - INFO - Response content extracted, length: 1337 characters
2025-11-23 12:10:12,417 - INFO - ================================================================================
2025-11-23 12:22:36,569 - INFO - ================================================================================
2025-11-23 12:22:36,569 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 4
2025-11-23 12:22:36,578 - INFO - AI analysis prompt loaded, length: 7470 characters
2025-11-23 12:22:36,578 - INFO - Report namespace created - date: 2025-11-23, time: 12:22:00, area: OPERATIONS, description length: 88
2025-11-23 12:22:36,578 - INFO - Rendered prompt length: 7505 characters
2025-11-23 12:22:36,578 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 12:22:36,578 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 12:22:36,578 - INFO - Attempting to initialize OpenAI client
2025-11-23 12:22:36,880 - INFO - OpenAI client initialized successfully
2025-11-23 12:22:36,880 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 12:22:36,880 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium
2025-11-23 12:23:00,578 - INFO - API request completed successfully
2025-11-23 12:23:00,578 - INFO - Response content extracted, length: 1832 characters
2025-11-23 12:23:00,578 - INFO - ================================================================================
2025-11-23 12:30:03,512 - INFO - ================================================================================
2025-11-23 12:30:03,512 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 5
2025-11-23 12:30:03,512 - INFO - AI analysis prompt loaded, length: 7559 characters
2025-11-23 12:30:03,512 - INFO - Report namespace created - date: 2025-11-23, time: 12:25:00, area: OPERATIONS, description length: 147
2025-11-23 12:30:03,512 - INFO - Rendered prompt length: 7653 characters
2025-11-23 12:30:03,512 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 12:30:03,512 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 12:30:03,512 - INFO - Attempting to initialize OpenAI client
2025-11-23 12:30:03,797 - INFO - OpenAI client initialized successfully
2025-11-23 12:30:03,807 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 12:30:03,807 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium, tools: [{'type': 'web_search'}]
2025-11-23 12:30:37,233 - INFO - API request completed successfully
2025-11-23 12:30:37,233 - INFO - Response content extracted, length: 2141 characters
2025-11-23 12:30:37,233 - INFO - ================================================================================
2025-11-23 16:16:07,453 - INFO - ================================================================================
2025-11-23 16:16:07,453 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 6
2025-11-23 16:16:07,453 - INFO - AI analysis prompt loaded, length: 7559 characters
2025-11-23 16:16:07,453 - INFO - Report namespace created - date: 2025-11-23, time: 16:15:00, area: OPERATIONS, description length: 347
2025-11-23 16:16:07,453 - INFO - Rendered prompt length: 7853 characters
2025-11-23 16:16:07,455 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-23 16:16:07,455 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-23 16:16:07,455 - INFO - Attempting to initialize OpenAI client
2025-11-23 16:16:07,803 - INFO - OpenAI client initialized successfully
2025-11-23 16:16:07,803 - INFO - Making API request to OpenAI responses endpoint
2025-11-23 16:16:07,803 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium, tools: [{'type': 'web_search'}]
2025-11-23 16:16:42,312 - INFO - API request completed successfully
2025-11-23 16:16:42,312 - INFO - Response content extracted, length: 2434 characters
2025-11-23 16:16:42,312 - INFO - ================================================================================
2025-11-25 10:56:11,558 - INFO - ================================================================================
2025-11-25 10:56:11,558 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 7
2025-11-25 10:56:11,558 - INFO - AI analysis prompt loaded, length: 7559 characters
2025-11-25 10:56:11,558 - INFO - Report namespace created - date: 2025-11-25, time: 10:55:00, area: OPERATIONS, description length: 91
2025-11-25 10:56:11,558 - INFO - Rendered prompt length: 7597 characters
2025-11-25 10:56:11,558 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-25 10:56:11,569 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-25 10:56:11,569 - INFO - Attempting to initialize OpenAI client
2025-11-25 10:56:11,897 - INFO - OpenAI client initialized successfully
2025-11-25 10:56:11,898 - INFO - Making API request to OpenAI responses endpoint
2025-11-25 10:56:11,898 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium, tools: [{'type': 'web_search'}]
2025-11-25 10:56:16,201 - INFO - API request completed successfully
2025-11-25 10:56:16,201 - INFO - Response content extracted, length: 54 characters
2025-11-25 10:56:16,201 - INFO - ================================================================================
2025-11-25 18:43:04,525 - INFO - ================================================================================
2025-11-25 18:43:04,525 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 4
2025-11-25 18:43:04,525 - INFO - AI analysis prompt loaded, length: 7559 characters
2025-11-25 18:43:04,525 - INFO - Report namespace created - date: 2025-11-25, time: 18:42:00, area: OPERATIONS, description length: 68
2025-11-25 18:43:04,525 - INFO - Rendered prompt length: 7574 characters
2025-11-25 18:43:04,525 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-25 18:43:04,525 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-25 18:43:04,525 - INFO - Attempting to initialize OpenAI client
2025-11-25 18:43:04,841 - INFO - OpenAI client initialized successfully
2025-11-25 18:43:04,841 - INFO - Making API request to OpenAI responses endpoint
2025-11-25 18:43:04,841 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium, tools: [{'type': 'web_search'}]
2025-11-25 18:43:09,670 - INFO - API request completed successfully
2025-11-25 18:43:09,670 - INFO - Response content extracted, length: 54 characters
2025-11-25 18:43:09,681 - INFO - ================================================================================
2025-11-25 18:51:13,919 - INFO - ================================================================================
2025-11-25 18:51:13,919 - INFO - Starting run_ai_analysis_for_voluntary_hazard_report for VHR ID: 5
2025-11-25 18:51:13,919 - INFO - AI analysis prompt loaded, length: 7559 characters
2025-11-25 18:51:13,919 - INFO - Report namespace created - date: 2025-11-25, time: 18:50:00, area: OPERATIONS, description length: 112
2025-11-25 18:51:13,919 - INFO - Rendered prompt length: 7618 characters
2025-11-25 18:51:13,919 - INFO - Retrieving OPENAI_API_KEY from environment variables
2025-11-25 18:51:13,919 - INFO - API key retrieved successfully (length: 164 characters)
2025-11-25 18:51:13,919 - INFO - Attempting to initialize OpenAI client
2025-11-25 18:51:14,202 - INFO - OpenAI client initialized successfully
2025-11-25 18:51:14,218 - INFO - Making API request to OpenAI responses endpoint
2025-11-25 18:51:14,218 - INFO - Model: gpt-5.1, reasoning: medium, text verbosity: medium, tools: [{'type': 'web_search'}]
2025-11-25 18:51:20,405 - INFO - API request completed successfully
2025-11-25 18:51:20,405 - INFO - Response content extracted, length: 54 characters
2025-11-25 18:51:20,405 - INFO - ================================================================================
